# uqlm: Uncertainty Quantification for Language Models

Welcome to the repository for `uqlm`, an open-source Python library for Large Language Model (LLM) hallucination detection using state-of-the-art uncertainty quantification techniques. This library is part of the framework presented in our paper, "Uncertainty Quantification for Language Models: Black-Box, White-Box, Judges, and Ensemble Methods" which is available on [arXiv](https://arxiv.org/).

## Repository Status

**Coming Soon!**

The code for this project is currently undergoing final internal review and is expected to be available by May 5th, 2025. We appreciate your patience and interest in our work.

## Contact

If you have any questions or would like to be notified when the code is available, please feel free to reach out to us at Dylan.Bouchard@CVSHealth.com or MohitSingh.Chauhan@CVSHealth.com.

## License

Apache 2.0

---

Thank you for your interest in `uqlm`. We look forward to sharing our work with you soon!
